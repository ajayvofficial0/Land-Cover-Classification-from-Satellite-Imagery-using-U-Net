{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eeab7f2-d0a1-41c3-b9a2-0c0f5dddcb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\trijal\\anaconda3\\lib\\site-packages (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision in c:\\users\\trijal\\anaconda3\\lib\\site-packages (0.21.0+cu126)\n",
      "Requirement already satisfied: pandas in c:\\users\\trijal\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\trijal\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\trijal\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision pandas pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2e9be9-4bd7-4253-bbbe-8364b2d555ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_colormap_from_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    colormap = {}\n",
    "    for i, row in df.iterrows():\n",
    "        rgb = (row['r'], row['g'], row['b'])\n",
    "        colormap[rgb] = i  # index as class label\n",
    "    return colormap\n",
    "\n",
    "colormap = get_colormap_from_csv(r\"C:\\Users\\Trijal\\Desktop\\DL U-net\\data\\class_dict.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e049ee6-9630-4504-8a4a-7e6cccbdfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class DeepGlobeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, colormap=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.filenames = sorted([f for f in os.listdir(root_dir) if f.endswith('_sat.jpg')])\n",
    "        self.transform = transform\n",
    "        self.colormap = colormap\n",
    "\n",
    "    def mask_to_class(self, mask):\n",
    "        mask = np.array(mask)\n",
    "        label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int64)\n",
    "        for rgb, idx in self.colormap.items():\n",
    "            matches = np.all(mask == rgb, axis=-1)\n",
    "            label_mask[matches] = idx\n",
    "        return torch.from_numpy(label_mask).long()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base = self.filenames[idx].replace('_sat.jpg', '')\n",
    "        img_path = os.path.join(self.root_dir, f\"{base}_sat.jpg\")\n",
    "        mask_path = os.path.join(self.root_dir, f\"{base}_mask.png\")\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('RGB')\n",
    "\n",
    "        # Apply same size to both\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = mask.resize((256, 256), resample=Image.NEAREST)\n",
    "\n",
    "        mask = self.mask_to_class(mask)  # Now the shape will match model output\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2321db70-b81d-41d3-88da-a146d9585994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(3, 64)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, 2)\n",
    "        self.dec4 = DoubleConv(1024, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        self.dec3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        self.dec2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        self.dec1 = DoubleConv(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "        return self.out(d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4ed16b-a045-419e-b1a8-1680858406e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = DeepGlobeDataset(r\"C:\\Users\\Trijal\\Desktop\\DL U-net\\data\\train\", transform=transform, colormap=colormap)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_classes=len(colormap)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a11127-3e01-465a-a6f7-1e348ea903c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Total Loss: 279.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Total Loss: 232.2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Total Loss: 212.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Total Loss: 200.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Total Loss: 188.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "    \n",
    "    for images, masks in progress_bar:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Total Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd9c680-bd44-4355-8a12-642ff2319979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1953589-6586-4e7a-bc44-ca29f6d63462",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DeepGlobeDataset(root_dir=r\"C:\\Users\\Trijal\\Desktop\\DL U-net\\data\\valid\", transform=transform, colormap=colormap)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bb6338d-8854-44c8-92d2-66f3816eda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segmentation(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    iou_scores = []\n",
    "    dice_scores = []\n",
    "    total_pixels = 0\n",
    "    correct_pixels = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            for pred, gt in zip(preds, masks):\n",
    "                total_pixels += gt.numel()\n",
    "                correct_pixels += (pred == gt).sum().item()\n",
    "\n",
    "                for cls in range(num_classes):\n",
    "                    pred_inds = (pred == cls)\n",
    "                    gt_inds = (gt == cls)\n",
    "\n",
    "                    intersection = (pred_inds & gt_inds).sum().item()\n",
    "                    union = (pred_inds | gt_inds).sum().item()\n",
    "                    dice = (2 * intersection) / (pred_inds.sum().item() + gt_inds.sum().item() + 1e-6)\n",
    "\n",
    "                    if union > 0:\n",
    "                        iou = intersection / (union + 1e-6)\n",
    "                        iou_scores.append(iou)\n",
    "                        dice_scores.append(dice)\n",
    "\n",
    "    pixel_accuracy = correct_pixels / total_pixels\n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "\n",
    "    print(f\"✅ Evaluation Metrics on Validation Set:\")\n",
    "    print(f\"  🔹 Pixel Accuracy      : {pixel_accuracy:.4f}\")\n",
    "    print(f\"  🔹 Mean IoU (Jaccard)  : {mean_iou:.4f}\")\n",
    "    print(f\"  🔹 Mean Dice (F1 Score): {mean_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c1c6db4-a021-4f8b-afe4-cfe29cc83c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation Metrics on Validation Set:\n",
      "  🔹 Pixel Accuracy      : 0.8915\n",
      "  🔹 Mean IoU (Jaccard)  : 0.3323\n",
      "  🔹 Mean Dice (F1 Score): 0.3786\n"
     ]
    }
   ],
   "source": [
    "evaluate_segmentation(model, val_loader, num_classes=len(colormap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d74972-72d2-4ba7-8806-7313958f7b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
